# Decision Tree Implementation

This folder contains an implementation of a decision tree in Python, specifically tailored to handle various scenarios with different types of features and output.

## Objective
The objective of this project is to complete the implementation of the decision tree in the `tree/base.py` file. The code should support the following cases:
1. Discrete features with discrete output
2. Discrete features with real output
3. Real features with discrete output
4. Real features with real output

## Features
- **Splitting Criteria:** The decision tree can use either Gini Index or Information Gain (Entropy) as the criteria for splitting in cases with discrete output, and Information Gain (MSE) for cases with real output.
- **Plotting:** The decision tree implementation includes functionality to plot or display the decision tree.

## Files
- **`tree/base.py`:** Completed the DecisionTree class in this file.
- **`tree/utils.py`:** Completed all utility functions required for the decision tree implementation.

## Usage
To check your solutions, run the `usage.py` file.


# Decision Tree Demonstration 

## Objective
To demonstrate the usage of this decision tree model on the automotive efficiency problem dataset and compare its performance with the decision tree module from scikit-learn.

## Tasks Completed
1. **Usage Demonstration:** The usage of the custom decision tree for the automotive efficiency problem dataset is demonstrated. This dataset can be accessed [here](https://archive.ics.uci.edu/ml/datasets/auto+mpg).
2. **Performance Comparison:** The performance of the custom decision tree model is compared with the decision tree module from scikit-learn.

## Usage
To see the usage of the custom decision tree for the automotive efficiency problem, refer to the provided code.

Thank you for your interest in this project!
